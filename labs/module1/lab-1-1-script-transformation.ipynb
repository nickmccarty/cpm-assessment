{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 1.1: Script to Application Transformation\n",
    "**Module 1 | Duration: 2-3 hours | Bridge: Scripts → Applications**\n",
    "\n",
    "## Learning Objectives\n",
    "- Transform monolithic scripts into modular applications\n",
    "- Apply separation of concerns principles\n",
    "- Implement object-oriented design patterns for AI applications\n",
    "- Create professional code organization structure\n",
    "\n",
    "## Scenario: Sarah's Productivity Challenge\n",
    "\n",
    "Meet Sarah, a freelance marketing consultant who approaches you with this request:\n",
    "\n",
    "*\"I've been using this Python script I found online to help with my work, but it's becoming a nightmare to modify. Every time I want to add a feature or fix something, I have to hunt through 200+ lines of mixed-up code. Can you help me organize this into something maintainable?\"*\n",
    "\n",
    "Your mission: Transform Sarah's chaotic script into a professional, modular application that she can easily understand, maintain, and enhance.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Analyzing the Problematic Script\n",
    "\n",
    "First, let's examine Sarah's current script. This represents the typical \"script chaos\" that happens when functionality grows organically without proper planning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sarah's Original Script - DON'T RUN THIS YET!\n",
    "# This is intentionally poorly organized to demonstrate the problems\n",
    "\n",
    "import openai\n",
    "import os\n",
    "import json\n",
    "import datetime\n",
    "from typing import List, Dict\n",
    "\n",
    "# Hardcoded configuration - Problem #1\n",
    "API_KEY = \"your-api-key-here\"  # Security issue!\n",
    "MODEL = \"gpt-3.5-turbo\"\n",
    "MAX_TOKENS = 1000\n",
    "TEMPERATURE = 0.7\n",
    "CONVERSATION_FILE = \"conversations.json\"\n",
    "\n",
    "# Global variables - Problem #2  \n",
    "conversation_history = []\n",
    "user_preferences = {}\n",
    "api_call_count = 0\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main function - doing too many things! - Problem #3\n",
    "    \"\"\"\n",
    "    global conversation_history, user_preferences, api_call_count\n",
    "    \n",
    "    print(\"Welcome to Sarah's AI Assistant!\")\n",
    "    \n",
    "    # Load conversation history - mixed with main logic\n",
    "    if os.path.exists(CONVERSATION_FILE):\n",
    "        try:\n",
    "            with open(CONVERSATION_FILE, 'r') as f:\n",
    "                conversation_history = json.load(f)\n",
    "        except:\n",
    "            print(\"Could not load conversation history\")\n",
    "            conversation_history = []\n",
    "    \n",
    "    # Set up OpenAI\n",
    "    openai.api_key = API_KEY\n",
    "    \n",
    "    while True:\n",
    "        user_input = input(\"\\nYou: \").strip()\n",
    "        \n",
    "        if user_input.lower() in ['quit', 'exit', 'bye']:\n",
    "            break\n",
    "            \n",
    "        if user_input.lower().startswith('/save '):\n",
    "            # Command handling mixed with main loop - Problem #4\n",
    "            filename = user_input[6:]\n",
    "            try:\n",
    "                with open(filename, 'w') as f:\n",
    "                    json.dump(conversation_history, f, indent=2)\n",
    "                print(f\"Conversation saved to {filename}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error saving file: {e}\")\n",
    "            continue\n",
    "        \n",
    "        if user_input.lower() == '/clear':\n",
    "            conversation_history = []\n",
    "            print(\"Conversation cleared\")\n",
    "            continue\n",
    "        \n",
    "        if user_input.lower() == '/stats':\n",
    "            print(f\"API calls made: {api_call_count}\")\n",
    "            print(f\"Conversation length: {len(conversation_history)}\")\n",
    "            continue\n",
    "        \n",
    "        # Build context from conversation history\n",
    "        messages = [{\"role\": \"system\", \"content\": \"You are a helpful AI assistant for a marketing consultant.\"}]\n",
    "        \n",
    "        # Add recent conversation history (last 10 exchanges)\n",
    "        recent_history = conversation_history[-20:] if len(conversation_history) > 20 else conversation_history\n",
    "        \n",
    "        for exchange in recent_history:\n",
    "            messages.append({\"role\": \"user\", \"content\": exchange[\"user\"]})\n",
    "            messages.append({\"role\": \"assistant\", \"content\": exchange[\"assistant\"]})\n",
    "        \n",
    "        messages.append({\"role\": \"user\", \"content\": user_input})\n",
    "        \n",
    "        # API call with minimal error handling - Problem #5\n",
    "        try:\n",
    "            response = openai.ChatCompletion.create(\n",
    "                model=MODEL,\n",
    "                messages=messages,\n",
    "                max_tokens=MAX_TOKENS,\n",
    "                temperature=TEMPERATURE\n",
    "            )\n",
    "            \n",
    "            assistant_response = response.choices[0].message.content\n",
    "            api_call_count += 1\n",
    "            \n",
    "            print(f\"\\nAI: {assistant_response}\")\n",
    "            \n",
    "            # Save to conversation history\n",
    "            conversation_history.append({\n",
    "                \"timestamp\": datetime.datetime.now().isoformat(),\n",
    "                \"user\": user_input,\n",
    "                \"assistant\": assistant_response\n",
    "            })\n",
    "            \n",
    "            # Auto-save conversation\n",
    "            try:\n",
    "                with open(CONVERSATION_FILE, 'w') as f:\n",
    "                    json.dump(conversation_history, f, indent=2)\n",
    "            except:\n",
    "                print(\"Warning: Could not save conversation\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error: {e}\")\n",
    "            print(\"Please try again.\")\n",
    "    \n",
    "    print(\"Goodbye!\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 🔍 Problem Analysis\n",
    "\n",
    "**Task 1.1**: Before we fix this script, let's identify the problems. In the cell below, list at least 5 major issues with Sarah's script:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your Analysis** (Replace this with your findings):\n",
    "\n",
    "1. **Problem 1**: _[Identify the first major issue]_\n",
    "2. **Problem 2**: _[Identify the second major issue]_\n",
    "3. **Problem 3**: _[Identify the third major issue]_\n",
    "4. **Problem 4**: _[Identify the fourth major issue]_\n",
    "5. **Problem 5**: _[Identify the fifth major issue]_\n",
    "\n",
    "**Impact on Sarah**: _[Explain how these problems affect Sarah's daily work]_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 2: Planning the Modular Architecture\n",
    "\n",
    "Now let's plan how to organize this code using professional principles. We'll apply the **separation of concerns** principle to create a clean, maintainable structure.\n",
    "\n",
    "### Architecture Planning Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 1.2**: Based on the functionality in Sarah's script, design a modular architecture. Fill in the table below:\n",
    "\n",
    "| Module Name | Responsibilities | Key Functions |\n",
    "|-------------|------------------|---------------|\n",
    "| `config.py` | Configuration management | _[List 2-3 key functions]_ |\n",
    "| `_____` | _[Your module name]_ | _[List responsibilities and functions]_ |\n",
    "| `_____` | _[Your module name]_ | _[List responsibilities and functions]_ |\n",
    "| `_____` | _[Your module name]_ | _[List responsibilities and functions]_ |\n",
    "| `main.py` | Application orchestration | _[List 2-3 key functions]_ |\n",
    "\n",
    "**Why this organization helps Sarah**:\n",
    "_[Explain how this structure makes the code easier to maintain and extend]_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 3: Implementation - Configuration Module\n",
    "\n",
    "Let's start with the foundation: proper configuration management. This solves the hardcoded values problem and makes the application secure and flexible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config.py - Configuration Management Module\n",
    "\n",
    "import os\n",
    "from dataclasses import dataclass\n",
    "from typing import Optional\n",
    "\n",
    "@dataclass\n",
    "class AIConfig:\n",
    "    \"\"\"\n",
    "    Configuration settings for AI Assistant.\n",
    "    Loads from environment variables with sensible defaults.\n",
    "    \"\"\"\n",
    "    api_key: str\n",
    "    model: str = \"gpt-3.5-turbo\"\n",
    "    max_tokens: int = 1000\n",
    "    temperature: float = 0.7\n",
    "    system_prompt: str = \"You are a helpful AI assistant for a marketing consultant.\"\n",
    "    \n",
    "    @classmethod\n",
    "    def from_environment(cls) -> 'AIConfig':\n",
    "        \"\"\"\n",
    "        Create configuration from environment variables.\n",
    "        Raises ValueError if required variables are missing.\n",
    "        \"\"\"\n",
    "        api_key = os.getenv('OPENAI_API_KEY')\n",
    "        if not api_key:\n",
    "            raise ValueError(\n",
    "                \"OPENAI_API_KEY environment variable is required. \"\n",
    "                \"Set it with: export OPENAI_API_KEY='your-key-here'\"\n",
    "            )\n",
    "        \n",
    "        return cls(\n",
    "            api_key=api_key,\n",
    "            model=os.getenv('AI_MODEL', 'gpt-3.5-turbo'),\n",
    "            max_tokens=int(os.getenv('MAX_TOKENS', '1000')),\n",
    "            temperature=float(os.getenv('TEMPERATURE', '0.7')),\n",
    "            system_prompt=os.getenv('SYSTEM_PROMPT', \n",
    "                                   \"You are a helpful AI assistant for a marketing consultant.\")\n",
    "        )\n",
    "\n",
    "@dataclass\n",
    "class AppConfig:\n",
    "    \"\"\"\n",
    "    Application-level configuration settings.\n",
    "    \"\"\"\n",
    "    conversation_file: str = \"conversations.json\"\n",
    "    max_history_context: int = 20\n",
    "    auto_save: bool = True\n",
    "    \n",
    "    @classmethod\n",
    "    def from_environment(cls) -> 'AppConfig':\n",
    "        \"\"\"Create app configuration from environment variables.\"\"\"\n",
    "        return cls(\n",
    "            conversation_file=os.getenv('CONVERSATION_FILE', 'conversations.json'),\n",
    "            max_history_context=int(os.getenv('MAX_HISTORY_CONTEXT', '20')),\n",
    "            auto_save=os.getenv('AUTO_SAVE', 'true').lower() == 'true'\n",
    "        )\n",
    "\n",
    "# Test the configuration module\n",
    "print(\"✓ Configuration module created!\")\n",
    "print(\"Next: Set your OPENAI_API_KEY environment variable to test this.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 🧪 Testing Configuration\n",
    "\n",
    "**Task 1.3**: Test the configuration module:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test configuration loading\n",
    "\n",
    "# For testing, let's temporarily set the API key\n",
    "import os\n",
    "os.environ['OPENAI_API_KEY'] = 'test-key-for-demo'  # Replace with real key for actual use\n",
    "\n",
    "try:\n",
    "    ai_config = AIConfig.from_environment()\n",
    "    app_config = AppConfig.from_environment()\n",
    "    \n",
    "    print(\"✓ Configuration loaded successfully!\")\n",
    "    print(f\"Model: {ai_config.model}\")\n",
    "    print(f\"Max tokens: {ai_config.max_tokens}\")\n",
    "    print(f\"Conversation file: {app_config.conversation_file}\")\n",
    "    \n",
    "except ValueError as e:\n",
    "    print(f\"❌ Configuration error: {e}\")\n",
    "\n",
    "# Clean up test environment variable\n",
    "del os.environ['OPENAI_API_KEY']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 4: Implementation - AI Client Module\n",
    "\n",
    "Now let's create a dedicated module for AI interactions. This encapsulates all the API complexity and provides a clean interface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ai_client.py - AI Service Integration Module\n",
    "\n",
    "import openai\n",
    "import time\n",
    "import logging\n",
    "from typing import List, Dict, Optional\n",
    "from dataclasses import dataclass\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "@dataclass\n",
    "class AIResponse:\n",
    "    \"\"\"\n",
    "    Structured response from AI service.\n",
    "    \"\"\"\n",
    "    content: str\n",
    "    success: bool\n",
    "    error_message: Optional[str] = None\n",
    "    tokens_used: int = 0\n",
    "    model_used: str = \"\"\n",
    "\n",
    "class AIClient:\n",
    "    \"\"\"\n",
    "    Professional AI client with robust error handling and retry logic.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, config):\n",
    "        \"\"\"Initialize AI client with configuration.\"\"\"\n",
    "        self.config = config\n",
    "        openai.api_key = config.api_key\n",
    "        self.call_count = 0\n",
    "        \n",
    "    def generate_response(self, \n",
    "                         user_message: str, \n",
    "                         conversation_history: List[Dict] = None,\n",
    "                         max_retries: int = 3) -> AIResponse:\n",
    "        \"\"\"\n",
    "        Generate AI response with robust error handling.\n",
    "        \n",
    "        Args:\n",
    "            user_message: The user's input message\n",
    "            conversation_history: Previous conversation context\n",
    "            max_retries: Maximum number of retry attempts\n",
    "            \n",
    "        Returns:\n",
    "            AIResponse object with result and metadata\n",
    "        \"\"\"\n",
    "        messages = self._build_messages(user_message, conversation_history)\n",
    "        \n",
    "        for attempt in range(max_retries):\n",
    "            try:\n",
    "                response = openai.ChatCompletion.create(\n",
    "                    model=self.config.model,\n",
    "                    messages=messages,\n",
    "                    max_tokens=self.config.max_tokens,\n",
    "                    temperature=self.config.temperature,\n",
    "                    timeout=30  # 30 second timeout\n",
    "                )\n",
    "                \n",
    "                self.call_count += 1\n",
    "                \n",
    "                return AIResponse(\n",
    "                    content=response.choices[0].message.content,\n",
    "                    success=True,\n",
    "                    tokens_used=response.usage.total_tokens,\n",
    "                    model_used=self.config.model\n",
    "                )\n",
    "                \n",
    "            except openai.error.RateLimitError:\n",
    "                wait_time = 2 ** attempt  # Exponential backoff\n",
    "                logger.warning(f\"Rate limit hit. Waiting {wait_time} seconds...\")\n",
    "                if attempt < max_retries - 1:\n",
    "                    time.sleep(wait_time)\n",
    "                    continue\n",
    "                else:\n",
    "                    return AIResponse(\n",
    "                        content=\"\",\n",
    "                        success=False,\n",
    "                        error_message=\"Rate limit exceeded. Please try again in a few minutes.\"\n",
    "                    )\n",
    "                    \n",
    "            except openai.error.APIError as e:\n",
    "                logger.error(f\"OpenAI API error on attempt {attempt + 1}: {e}\")\n",
    "                if attempt == max_retries - 1:\n",
    "                    return AIResponse(\n",
    "                        content=\"\",\n",
    "                        success=False,\n",
    "                        error_message=\"AI service is temporarily unavailable. Please try again later.\"\n",
    "                    )\n",
    "                    \n",
    "            except openai.error.InvalidRequestError as e:\n",
    "                logger.error(f\"Invalid request: {e}\")\n",
    "                return AIResponse(\n",
    "                    content=\"\",\n",
    "                    success=False,\n",
    "                    error_message=\"Invalid request. Please check your input and try again.\"\n",
    "                )\n",
    "                \n",
    "            except Exception as e:\n",
    "                logger.error(f\"Unexpected error on attempt {attempt + 1}: {e}\")\n",
    "                if attempt == max_retries - 1:\n",
    "                    return AIResponse(\n",
    "                        content=\"\",\n",
    "                        success=False,\n",
    "                        error_message=\"An unexpected error occurred. Please try again.\"\n",
    "                    )\n",
    "                    \n",
    "        # This should not be reached, but just in case\n",
    "        return AIResponse(\n",
    "            content=\"\",\n",
    "            success=False,\n",
    "            error_message=\"Maximum retry attempts exceeded.\"\n",
    "        )\n",
    "    \n",
    "    def _build_messages(self, user_message: str, history: List[Dict] = None) -> List[Dict]:\n",
    "        \"\"\"\n",
    "        Build properly formatted message list for OpenAI API.\n",
    "        \"\"\"\n",
    "        messages = [{\"role\": \"system\", \"content\": self.config.system_prompt}]\n",
    "        \n",
    "        # Add conversation history if provided\n",
    "        if history:\n",
    "            for exchange in history:\n",
    "                messages.append({\"role\": \"user\", \"content\": exchange[\"user\"]})\n",
    "                messages.append({\"role\": \"assistant\", \"content\": exchange[\"assistant\"]})\n",
    "        \n",
    "        # Add current user message\n",
    "        messages.append({\"role\": \"user\", \"content\": user_message})\n",
    "        \n",
    "        return messages\n",
    "    \n",
    "    def get_stats(self) -> Dict[str, int]:\n",
    "        \"\"\"\n",
    "        Get usage statistics.\n",
    "        \"\"\"\n",
    "        return {\n",
    "            \"api_calls_made\": self.call_count,\n",
    "            \"model_used\": self.config.model\n",
    "        }\n",
    "\n",
    "print(\"✓ AI Client module created!\")\n",
    "print(\"This module provides professional error handling and retry logic.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 1.4**: Compare the AI client module to Sarah's original API handling. What improvements do you see?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your Comparison** (Replace this with your analysis):\n",
    "\n",
    "**Improvements in the AI Client Module**:\n",
    "1. _[List improvement #1]_\n",
    "2. _[List improvement #2]_\n",
    "3. _[List improvement #3]_\n",
    "\n",
    "**Benefits for Sarah**:\n",
    "_[Explain how these improvements help Sarah in her daily work]_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 5: Implementation - Conversation Manager\n",
    "\n",
    "Let's create a dedicated module for managing conversation history and persistence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conversation_manager.py - Data Persistence and History Management\n",
    "\n",
    "import json\n",
    "import os\n",
    "from datetime import datetime\n",
    "from typing import List, Dict, Optional\n",
    "from pathlib import Path\n",
    "\n",
    "class ConversationManager:\n",
    "    \"\"\"\n",
    "    Manages conversation history with robust file operations.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, config):\n",
    "        \"\"\"Initialize conversation manager with configuration.\"\"\"\n",
    "        self.config = config\n",
    "        self.file_path = Path(config.conversation_file)\n",
    "        self.conversations = self._load_conversations()\n",
    "        \n",
    "    def _load_conversations(self) -> List[Dict]:\n",
    "        \"\"\"\n",
    "        Load existing conversations from file with error handling.\n",
    "        \"\"\"\n",
    "        if not self.file_path.exists():\n",
    "            return []\n",
    "        \n",
    "        try:\n",
    "            with open(self.file_path, 'r', encoding='utf-8') as f:\n",
    "                data = json.load(f)\n",
    "                # Validate data structure\n",
    "                if isinstance(data, list):\n",
    "                    return data\n",
    "                else:\n",
    "                    print(f\"Warning: Invalid conversation file format. Starting fresh.\")\n",
    "                    return []\n",
    "        except json.JSONDecodeError:\n",
    "            print(f\"Warning: Corrupted conversation file. Creating backup and starting fresh.\")\n",
    "            # Create backup of corrupted file\n",
    "            backup_path = self.file_path.with_suffix('.backup')\n",
    "            self.file_path.rename(backup_path)\n",
    "            return []\n",
    "        except Exception as e:\n",
    "            print(f\"Warning: Could not load conversations: {e}\")\n",
    "            return []\n",
    "    \n",
    "    def add_exchange(self, user_message: str, ai_response: str) -> None:\n",
    "        \"\"\"\n",
    "        Add a conversation exchange to history.\n",
    "        \"\"\"\n",
    "        exchange = {\n",
    "            \"timestamp\": datetime.now().isoformat(),\n",
    "            \"user\": user_message,\n",
    "            \"assistant\": ai_response\n",
    "        }\n",
    "        \n",
    "        self.conversations.append(exchange)\n",
    "        \n",
    "        # Auto-save if enabled\n",
    "        if self.config.auto_save:\n",
    "            self._save_conversations()\n",
    "    \n",
    "    def get_recent_context(self, max_exchanges: Optional[int] = None) -> List[Dict]:\n",
    "        \"\"\"\n",
    "        Get recent conversation context for AI.\n",
    "        \"\"\"\n",
    "        limit = max_exchanges or self.config.max_history_context\n",
    "        return self.conversations[-limit:] if self.conversations else []\n",
    "    \n",
    "    def clear_history(self) -> None:\n",
    "        \"\"\"\n",
    "        Clear conversation history.\n",
    "        \"\"\"\n",
    "        self.conversations = []\n",
    "        if self.config.auto_save:\n",
    "            self._save_conversations()\n",
    "    \n",
    "    def save_to_file(self, filename: str) -> bool:\n",
    "        \"\"\"\n",
    "        Save conversations to a specific file.\n",
    "        \n",
    "        Returns:\n",
    "            True if successful, False otherwise\n",
    "        \"\"\"\n",
    "        try:\n",
    "            save_path = Path(filename)\n",
    "            with open(save_path, 'w', encoding='utf-8') as f:\n",
    "                json.dump(self.conversations, f, indent=2, ensure_ascii=False)\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            print(f\"Error saving to {filename}: {e}\")\n",
    "            return False\n",
    "    \n",
    "    def _save_conversations(self) -> None:\n",
    "        \"\"\"\n",
    "        Save conversations to default file.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Ensure directory exists\n",
    "            self.file_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "            \n",
    "            with open(self.file_path, 'w', encoding='utf-8') as f:\n",
    "                json.dump(self.conversations, f, indent=2, ensure_ascii=False)\n",
    "        except Exception as e:\n",
    "            print(f\"Warning: Could not auto-save conversations: {e}\")\n",
    "    \n",
    "    def get_stats(self) -> Dict[str, any]:\n",
    "        \"\"\"\n",
    "        Get conversation statistics.\n",
    "        \"\"\"\n",
    "        if not self.conversations:\n",
    "            return {\n",
    "                \"total_exchanges\": 0,\n",
    "                \"first_conversation\": None,\n",
    "                \"last_conversation\": None\n",
    "            }\n",
    "        \n",
    "        return {\n",
    "            \"total_exchanges\": len(self.conversations),\n",
    "            \"first_conversation\": self.conversations[0][\"timestamp\"],\n",
    "            \"last_conversation\": self.conversations[-1][\"timestamp\"]\n",
    "        }\n",
    "\n",
    "print(\"✓ Conversation Manager module created!\")\n",
    "print(\"This module handles all data persistence with proper error handling.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 6: Implementation - Main Application Class\n",
    "\n",
    "Now let's create the main application class that orchestrates all the modules. This is where object-oriented design really shines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ai_assistant.py - Main Application Class\n",
    "\n",
    "from typing import Optional\n",
    "\n",
    "class AIAssistant:\n",
    "    \"\"\"\n",
    "    Main AI Assistant application class.\n",
    "    Orchestrates all components and provides high-level interface.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, ai_config, app_config):\n",
    "        \"\"\"Initialize AI Assistant with configuration.\"\"\"\n",
    "        self.ai_config = ai_config\n",
    "        self.app_config = app_config\n",
    "        \n",
    "        # Initialize components\n",
    "        self.ai_client = AIClient(ai_config)\n",
    "        self.conversation_manager = ConversationManager(app_config)\n",
    "        \n",
    "    def chat(self, user_message: str) -> str:\n",
    "        \"\"\"\n",
    "        Process a chat message and return response.\n",
    "        \n",
    "        Args:\n",
    "            user_message: User's input message\n",
    "            \n",
    "        Returns:\n",
    "            AI response string\n",
    "        \"\"\"\n",
    "        # Get conversation context\n",
    "        context = self.conversation_manager.get_recent_context()\n",
    "        \n",
    "        # Get AI response\n",
    "        ai_response = self.ai_client.generate_response(user_message, context)\n",
    "        \n",
    "        if ai_response.success:\n",
    "            # Save successful conversation\n",
    "            self.conversation_manager.add_exchange(user_message, ai_response.content)\n",
    "            return ai_response.content\n",
    "        else:\n",
    "            # Return error message without saving\n",
    "            return f\"Sorry, I encountered an error: {ai_response.error_message}\"\n",
    "    \n",
    "    def execute_command(self, command: str) -> str:\n",
    "        \"\"\"\n",
    "        Execute special commands.\n",
    "        \n",
    "        Args:\n",
    "            command: Command string (e.g., '/clear', '/stats', '/save filename')\n",
    "            \n",
    "        Returns:\n",
    "            Command result message\n",
    "        \"\"\"\n",
    "        command = command.strip().lower()\n",
    "        \n",
    "        if command == '/clear':\n",
    "            self.conversation_manager.clear_history()\n",
    "            return \"✓ Conversation history cleared.\"\n",
    "        \n",
    "        elif command == '/stats':\n",
    "            ai_stats = self.ai_client.get_stats()\n",
    "            conv_stats = self.conversation_manager.get_stats()\n",
    "            \n",
    "            return f\"\"\"📊 Assistant Statistics:\n",
    "• API calls made: {ai_stats['api_calls_made']}\n",
    "• Model: {ai_stats['model_used']}\n",
    "• Total conversations: {conv_stats['total_exchanges']}\n",
    "• First conversation: {conv_stats.get('first_conversation', 'None')}\n",
    "• Last conversation: {conv_stats.get('last_conversation', 'None')}\"\"\"\n",
    "        \n",
    "        elif command.startswith('/save '):\n",
    "            filename = command[6:].strip()\n",
    "            if not filename:\n",
    "                return \"❌ Please specify a filename: /save filename.json\"\n",
    "            \n",
    "            success = self.conversation_manager.save_to_file(filename)\n",
    "            if success:\n",
    "                return f\"✓ Conversation saved to {filename}\"\n",
    "            else:\n",
    "                return f\"❌ Failed to save conversation to {filename}\"\n",
    "        \n",
    "        elif command == '/help':\n",
    "            return \"\"\"🤖 AI Assistant Commands:\n",
    "• /help - Show this help message\n",
    "• /clear - Clear conversation history\n",
    "• /stats - Show usage statistics\n",
    "• /save <filename> - Save conversation to file\n",
    "• /quit or /exit - Exit the assistant\n",
    "\n",
    "Just type your message to chat with the AI!\"\"\"\n",
    "        \n",
    "        else:\n",
    "            return f\"❌ Unknown command: {command}. Type /help for available commands.\"\n",
    "    \n",
    "    def is_command(self, user_input: str) -> bool:\n",
    "        \"\"\"\n",
    "        Check if user input is a command.\n",
    "        \n",
    "        Args:\n",
    "            user_input: User's input string\n",
    "            \n",
    "        Returns:\n",
    "            True if input is a command, False otherwise\n",
    "        \"\"\"\n",
    "        return user_input.strip().startswith('/')\n",
    "    \n",
    "    def is_exit_command(self, user_input: str) -> bool:\n",
    "        \"\"\"\n",
    "        Check if user input is an exit command.\n",
    "        \n",
    "        Args:\n",
    "            user_input: User's input string\n",
    "            \n",
    "        Returns:\n",
    "            True if input is an exit command, False otherwise\n",
    "        \"\"\"\n",
    "        exit_commands = ['/quit', '/exit', 'quit', 'exit', 'bye']\n",
    "        return user_input.strip().lower() in exit_commands\n",
    "\n",
    "print(\"✓ AI Assistant main class created!\")\n",
    "print(\"This class orchestrates all components with clean separation of concerns.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 7: Implementation - Clean Main Entry Point\n",
    "\n",
    "Finally, let's create a clean, simple main entry point that ties everything together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main.py - Clean Application Entry Point\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main application entry point with proper error handling.\n",
    "    \"\"\"\n",
    "    print(\"🤖 Sarah's AI Assistant v2.0 - Professional Edition\")\n",
    "    print(\"Type /help for commands, or just start chatting!\")\n",
    "    print(\"\")\n",
    "    \n",
    "    try:\n",
    "        # Load configuration\n",
    "        ai_config = AIConfig.from_environment()\n",
    "        app_config = AppConfig.from_environment()\n",
    "        \n",
    "        # Initialize assistant\n",
    "        assistant = AIAssistant(ai_config, app_config)\n",
    "        \n",
    "        print(\"✓ Assistant initialized successfully!\")\n",
    "        print(f\"✓ Using model: {ai_config.model}\")\n",
    "        print(f\"✓ Conversation file: {app_config.conversation_file}\")\n",
    "        print()\n",
    "        \n",
    "        # Main interaction loop\n",
    "        while True:\n",
    "            try:\n",
    "                user_input = input(\"You: \").strip()\n",
    "                \n",
    "                if not user_input:\n",
    "                    continue\n",
    "                \n",
    "                if assistant.is_exit_command(user_input):\n",
    "                    print(\"\\n👋 Thank you for using Sarah's AI Assistant!\")\n",
    "                    break\n",
    "                \n",
    "                if assistant.is_command(user_input):\n",
    "                    response = assistant.execute_command(user_input)\n",
    "                else:\n",
    "                    response = assistant.chat(user_input)\n",
    "                \n",
    "                print(f\"\\nAI: {response}\\n\")\n",
    "                \n",
    "            except KeyboardInterrupt:\n",
    "                print(\"\\n\\n👋 Goodbye!\")\n",
    "                break\n",
    "            except Exception as e:\n",
    "                print(f\"\\n❌ Unexpected error: {e}\")\n",
    "                print(\"Please try again or type /help for assistance.\\n\")\n",
    "                \n",
    "    except ValueError as e:\n",
    "        print(f\"\\n❌ Configuration error: {e}\")\n",
    "        print(\"Please check your environment variables and try again.\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\n❌ Failed to initialize assistant: {e}\")\n",
    "        print(\"Please check your setup and try again.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n",
    "print(\"✓ Clean main entry point created!\")\n",
    "print(\"Compare this to the original 200+ line monolithic script!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 8: Testing the Transformation\n",
    "\n",
    "Let's test our refactored application to ensure it works correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the refactored application\n",
    "\n",
    "print(\"🧪 Testing the Refactored AI Assistant\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Test configuration loading (with mock key for demonstration)\n",
    "import os\n",
    "os.environ['OPENAI_API_KEY'] = 'test-key-demo'  # Replace with real key\n",
    "\n",
    "try:\n",
    "    # Initialize configurations\n",
    "    ai_config = AIConfig.from_environment()\n",
    "    app_config = AppConfig.from_environment()\n",
    "    \n",
    "    print(\"✓ Configuration loading: PASSED\")\n",
    "    \n",
    "    # Initialize assistant\n",
    "    assistant = AIAssistant(ai_config, app_config)\n",
    "    print(\"✓ Assistant initialization: PASSED\")\n",
    "    \n",
    "    # Test command processing\n",
    "    test_commands = [\n",
    "        ('/help', 'Help command'),\n",
    "        ('/stats', 'Statistics command'),\n",
    "        ('/clear', 'Clear command')\n",
    "    ]\n",
    "    \n",
    "    for command, description in test_commands:\n",
    "        result = assistant.execute_command(command)\n",
    "        print(f\"✓ {description}: PASSED\")\n",
    "    \n",
    "    # Test command detection\n",
    "    assert assistant.is_command('/help') == True\n",
    "    assert assistant.is_command('hello') == False\n",
    "    assert assistant.is_exit_command('quit') == True\n",
    "    assert assistant.is_exit_command('hello') == False\n",
    "    \n",
    "    print(\"✓ Command detection: PASSED\")\n",
    "    \n",
    "    print(\"\\n🎉 ALL TESTS PASSED!\")\n",
    "    print(\"The refactored application is working correctly.\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ Test failed: {e}\")\n",
    "\n",
    "# Clean up\n",
    "del os.environ['OPENAI_API_KEY']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 9: Before vs After Comparison\n",
    "\n",
    "Let's analyze the transformation we've achieved.\n",
    "\n",
    "**Task 1.5**: Complete the comparison table below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 📊 Transformation Analysis\n",
    "\n",
    "| Aspect | Original Script | Refactored Application |\n",
    "|--------|-----------------|------------------------|\n",
    "| **Lines of Code** | 200+ lines in 1 file | _[Count the lines in your modules]_ |\n",
    "| **Number of Files** | 1 monolithic file | _[Count your modules]_ |\n",
    "| **Error Handling** | Basic try/catch | _[Describe your error handling]_ |\n",
    "| **Configuration** | Hardcoded values | _[Describe your config system]_ |\n",
    "| **Testability** | Nearly impossible | _[Describe testing improvements]_ |\n",
    "| **Maintainability** | Very difficult | _[Describe maintenance improvements]_ |\n",
    "| **Reusability** | Cannot reuse components | _[Describe reusability gains]_ |\n",
    "| **Documentation** | Minimal comments | _[Describe your documentation]_ |\n",
    "\n",
    "### Benefits for Sarah\n",
    "\n",
    "**Task 1.6**: Explain how this refactoring helps Sarah with her specific challenges:\n",
    "\n",
    "1. **Adding New Features**: _[How is this now easier?]_\n",
    "2. **Fixing Problems**: _[How is debugging improved?]_\n",
    "3. **Understanding the Code**: _[How is the code more readable?]_\n",
    "4. **Sharing with Others**: _[How can others now use/modify the code?]_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 10: Extension Challenge (Advanced)\n",
    "\n",
    "**Task 1.7** (Optional): Choose one of these enhancements to implement:\n",
    "\n",
    "1. **Logging System**: Add comprehensive logging to track usage and debug issues\n",
    "2. **User Profiles**: Allow multiple users to have separate conversation histories\n",
    "3. **Export Features**: Add ability to export conversations in different formats (PDF, HTML, etc.)\n",
    "4. **Plugin System**: Create a simple plugin architecture for extending functionality\n",
    "\n",
    "Implement your chosen enhancement in the cell below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your enhancement implementation here\n",
    "# Choose one of the challenges above and implement it\n",
    "\n",
    "print(\"Enhancement chosen: [Your choice]\")\n",
    "print(\"Implementation: [Describe what you built]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 🎯 Lab Summary and Reflection\n",
    "\n",
    "### What You've Accomplished\n",
    "\n",
    "In this lab, you've successfully transformed a chaotic 200+ line monolithic script into a professional, modular application. You've demonstrated:\n",
    "\n",
    "- ✅ **Separation of Concerns**: Each module has a single, clear responsibility\n",
    "- ✅ **Object-Oriented Design**: Clean classes that encapsulate functionality\n",
    "- ✅ **Error Handling**: Robust error management and user feedback\n",
    "- ✅ **Configuration Management**: Secure, flexible configuration system\n",
    "- ✅ **Professional Practices**: Code organization that scales and maintains easily\n",
    "\n",
    "### Real-World Impact\n",
    "\n",
    "Sarah can now:\n",
    "- **Easily add new features** by modifying specific modules\n",
    "- **Quickly fix problems** by knowing exactly where to look\n",
    "- **Share her tool with others** through clear documentation and structure\n",
    "- **Scale her application** as her needs grow\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "This foundation prepares you for:\n",
    "- Building command-line interfaces (Lab 1.5)\n",
    "- Creating web interfaces with Gradio (Lab 1.6)\n",
    "- Implementing comprehensive testing strategies\n",
    "- Deploying applications professionally\n",
    "\n",
    "### Professional Skills Developed\n",
    "\n",
    "- **Code Architecture**: Designing maintainable software systems\n",
    "- **Refactoring**: Improving code without changing functionality\n",
    "- **Error Handling**: Building robust, user-friendly applications\n",
    "- **Documentation**: Creating code that others can understand and use\n",
    "\n",
    "**Congratulations!** You've completed the crucial transformation from script writer to application builder. This is a fundamental skill that will serve you throughout your AI development career."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}